interactions:
- request:
    body: '{"messages": [{"role": "user", "content": ""}, {"role": "assistant", "content":
      " "}, {"role": "user", "content": "\n"}], "model": "meta-llama/Meta-Llama-3.1-8B-Instruct",
      "stream": false}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '188'
      content-type:
      - application/json
      host:
      - api.deepinfra.com
      user-agent:
      - OpenAI/Python 1.50.1
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.50.1
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.10
    method: POST
    uri: https://api.deepinfra.com/v1/openai/chat/completions
  response:
    body:
      string: '{"id":"chatcmpl-c2ccf904d1164d8cb76c6c12d11f540d","object":"chat.completion","created":1729111885,"model":"meta-llama/Meta-Llama-3.1-8B-Instruct","choices":[{"index":0,"message":{"role":"assistant","content":"It
        seems like you started to ask a question or make a statement, but it got cut
        off. Can you please complete your thought or clarify what you would like to
        talk about? I''m here to help with any questions or topics you''d like to
        discuss.","name":null,"tool_calls":null},"finish_reason":"stop"}],"usage":{"prompt_tokens":20,"total_tokens":72,"completion_tokens":52,"estimated_cost":3.959999999999999e-06}}'
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '612'
      Content-Type:
      - application/json
      Date:
      - Wed, 16 Oct 2024 20:51:25 GMT
      server:
      - uvicorn
      x-robots-tag:
      - noindex
    status:
      code: 200
      message: OK
version: 1
