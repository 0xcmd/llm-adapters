interactions:
- request:
    body: '{"messages": [{"role": "user", "content": ""}, {"role": "assistant", "content":
      " "}, {"role": "user", "content": "\n"}], "model": "meta-llama/Meta-Llama-3.1-405B-Instruct",
      "stream": false}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br
      connection:
      - keep-alive
      content-length:
      - '190'
      content-type:
      - application/json
      host:
      - api.deepinfra.com
      user-agent:
      - AsyncOpenAI/Python 1.53.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.53.0
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.10
    method: POST
    uri: https://api.deepinfra.com/v1/openai/chat/completions
  response:
    body:
      string: '{"id":"chatcmpl-e6825257aa474a2d9a1ab542928cbe84","object":"chat.completion","created":1730332159,"model":"meta-llama/Meta-Llama-3.1-405B-Instruct","choices":[{"index":0,"message":{"role":"assistant","content":"It
        seems like you haven''t asked a question or provided any context for me to
        help you with. Please feel free to ask me anything or share what''s on your
        mind, and I''ll do my best to assist you!","name":null,"tool_calls":null},"finish_reason":"stop"}],"usage":{"prompt_tokens":20,"total_tokens":65,"completion_tokens":45,"estimated_cost":0.00011635}}'
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '559'
      Content-Type:
      - application/json
      Date:
      - Wed, 30 Oct 2024 23:49:19 GMT
      server:
      - uvicorn
      x-robots-tag:
      - noindex
    status:
      code: 200
      message: OK
version: 1
