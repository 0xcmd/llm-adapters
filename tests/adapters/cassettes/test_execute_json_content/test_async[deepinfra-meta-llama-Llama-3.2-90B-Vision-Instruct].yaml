interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "Hi\nHi"}], "model": "meta-llama/Llama-3.2-90B-Vision-Instruct",
      "stream": false}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '123'
      content-type:
      - application/json
      host:
      - api.deepinfra.com
      user-agent:
      - AsyncOpenAI/Python 1.50.1
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.50.1
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.10
    method: POST
    uri: https://api.deepinfra.com/v1/openai/chat/completions
  response:
    body:
      string: '{"id":"chatcmpl-ed792a0ecbda4827b634d087d11e2462","object":"chat.completion","created":1729112371,"model":"meta-llama/Llama-3.2-90B-Vision-Instruct","choices":[{"index":0,"message":{"role":"assistant","content":"Hi
        back at you! It seems like you''re feeling extra friendly today with the double
        \"Hi\". Is there something on your mind that you''d like to chat about, or
        are you just looking for some casual conversation?","name":null,"tool_calls":null},"finish_reason":"stop"}],"usage":{"prompt_tokens":13,"total_tokens":57,"completion_tokens":44,"estimated_cost":2.215e-05}}'
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '573'
      Content-Type:
      - application/json
      Date:
      - Wed, 16 Oct 2024 20:59:31 GMT
      server:
      - uvicorn
      x-robots-tag:
      - noindex
    status:
      code: 200
      message: OK
version: 1
