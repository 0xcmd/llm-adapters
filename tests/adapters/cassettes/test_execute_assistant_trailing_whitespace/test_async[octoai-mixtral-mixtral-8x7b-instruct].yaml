interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "Hi"}, {"role": "assistant",
      "content": "Hi "}], "model": "mixtral-8x7b-instruct", "stream": false}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '141'
      content-type:
      - application/json
      host:
      - text.octoai.run
      user-agent:
      - AsyncOpenAI/Python 1.50.1
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.50.1
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.10
    method: POST
    uri: https://text.octoai.run/v1/chat/completions
  response:
    body:
      string: '{"id":"chatcmpl-de7ce6806bee478c8633fb05ccfb16cd","object":"chat.completion","created":1729025810,"model":"mixtral-8x7b-instruct","choices":[{"index":0,"message":{"role":"assistant","content":"
        There! How can I help you today? Is there a particular topic or question you''d
        like to discuss? I''m here to assist with any questions you have to the best
        of my ability.\n\nIf you''re interested in learning more about me, I''m a
        large language model developed by Mistral AI, a leading AI company based in
        Paris. I''m trained on a wide variety of internet text and have been designed
        to be able to assist with a broad range of tasks and questions. I''m here
        to provide accurate and helpful information, so please don''t hesitate to
        ask me anything. I''m looking forward to our conversation!"},"logprobs":null,"finish_reason":"stop"}],"usage":{"prompt_tokens":12,"completion_tokens":136,"total_tokens":148}}'
    headers:
      Connection:
      - keep-alive
      Content-Length:
      - '893'
      Content-Type:
      - application/json
      Date:
      - Tue, 15 Oct 2024 20:56:49 GMT
      Server:
      - uvicorn
      Vary:
      - Origin
      Via:
      - kong/3.2.2
      X-Kong-Proxy-Latency:
      - '1'
      X-Kong-Upstream-Latency:
      - '2027'
      X-Ratelimit-Limit:
      - '4'
      X-Ratelimit-Remaining:
      - '3'
      X-Ratelimit-Reset:
      - '1729025811'
      X-User-Request-Id:
      - ''
    status:
      code: 200
      message: OK
version: 1
