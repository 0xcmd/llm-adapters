interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "Hi, use json"}], "model": "gpt-35-turbo",
      "response_format": {"type": "json_object"}}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      api-key:
      - b22bea4270b74a7e9eb3b2c74ee66db9
      connection:
      - keep-alive
      content-length:
      - '128'
      content-type:
      - application/json
      host:
      - martiantest.openai.azure.com
      user-agent:
      - AsyncAzureOpenAI/Python 1.34.0
      x-stainless-arch:
      - x64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.34.0
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.9
    method: POST
    uri: https://martiantest.openai.azure.com//openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-02-15-preview
  response:
    body:
      string: "{\n  \"error\": {\n    \"message\": \"Invalid parameter: 'response_format'
        of type 'json_object' is not supported with this model.\",\n    \"type\":
        \"invalid_request_error\",\n    \"param\": \"response_format\",\n    \"code\":
        null\n  }\n}\n"
    headers:
      Content-Length:
      - '218'
      Content-Type:
      - application/json
      Date:
      - Mon, 24 Jun 2024 06:04:14 GMT
      Strict-Transport-Security:
      - max-age=31536000; includeSubDomains; preload
      access-control-allow-origin:
      - '*'
      apim-request-id:
      - 2b215810-5a12-4fa1-a783-fd4b5002c371
      azureml-model-session:
      - turbo-0301-9d4f8a02
      ms-azureml-model-error-reason:
      - model_error
      ms-azureml-model-error-statuscode:
      - '400'
      x-content-type-options:
      - nosniff
      x-ms-client-request-id:
      - 2b215810-5a12-4fa1-a783-fd4b5002c371
      x-ms-rai-invoked:
      - 'true'
      x-ms-region:
      - East US
      x-ratelimit-remaining-requests:
      - '238'
      x-ratelimit-remaining-tokens:
      - '238904'
      x-request-id:
      - 2f90a7e5-351e-4565-a2d8-7a7160513665
    status:
      code: 400
      message: model_error
version: 1
