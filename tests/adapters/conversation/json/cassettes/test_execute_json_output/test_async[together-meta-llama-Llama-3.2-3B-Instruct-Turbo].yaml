interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "Hi, use json"}], "model": "meta-llama/Llama-3.2-3B-Instruct-Turbo",
      "response_format": {"type": "json_object"}, "stream": false}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, br
      connection:
      - keep-alive
      content-length:
      - '171'
      content-type:
      - application/json
      host:
      - api.together.xyz
      user-agent:
      - AsyncOpenAI/Python 1.54.1
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.54.1
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.10
    method: POST
    uri: https://api.together.xyz/chat/completions
  response:
    body:
      string: "{\n  \"error\": {\n    \"message\": \"meta-llama/Llama-3.2-3B-Instruct-Turbo
        is not supported for JSON mode/function calling\",\n    \"type\": \"invalid_request_error\",\n
        \   \"param\": null,\n    \"code\": \"constraints_model\"\n  }\n}"
    headers:
      CF-Cache-Status:
      - DYNAMIC
      CF-RAY:
      - 8de9e703b88dcfa8-SJC
      Connection:
      - keep-alive
      Content-Length:
      - '213'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Thu, 07 Nov 2024 02:30:37 GMT
      Server:
      - cloudflare
      Strict-Transport-Security:
      - max-age=2592000; includeSubDomains
      access-control-allow-origin:
      - '*'
      alt-svc:
      - h3=":443"; ma=86400
      etag:
      - W/"d5-4VbvaxyXhE1KWZToFRMPqrhSXLU"
      x-api-received:
      - '2024-11-07T02:30:37.417Z'
    status:
      code: 400
      message: Bad Request
version: 1
